---
marp: true
theme: default
paginate: true
backgroundColor: #fff
backgroundImage: url('https://marp.app/assets/hero-background.svg')
style: |
  section {
    font-size: 28px;
  }
  h1 {
    color: #FF6B35;
  }
  h2 {
    color: #004E98;
  }
  .columns {
    display: grid;
    grid-template-columns: repeat(2, minmax(0, 1fr));
    gap: 1rem;
  }
---

<!-- _class: lead -->

# MiniMax M2 æ¨¡å‹é€‚é… AWS Trainium2

## æŠ€æœ¯æ–¹æ¡ˆä¸å®æ–½æŠ¥å‘Š

**ä» Qwen3 MoE åˆ° MiniMax M2 (230B)**

---

## ğŸ“‹ è®®ç¨‹

1. **é¡¹ç›®èƒŒæ™¯ä¸ç›®æ ‡**
2. **æ¨¡å‹æ¶æ„å¯¹æ¯”åˆ†æ**
3. **æŠ€æœ¯å®æ–½è·¯çº¿**
4. **å…³é”®é—®é¢˜æ·±åº¦å‰–æ**
5. **æ€§èƒ½å½±å“è¯„ä¼°**
6. **æˆæœå±•ç¤º**
7. **ä¼˜åŒ–å»ºè®®ä¸å±•æœ›**

---

<!-- _class: lead -->

# 1. é¡¹ç›®èƒŒæ™¯ä¸ç›®æ ‡

---

## é¡¹ç›®æ¦‚è¿°

<div class="columns">
<div>

### ğŸ¯ ç›®æ ‡
- **è¿ç§»**: GPU â†’ Trainium2
- **æ¨¡å‹**: MiniMax M2 (230B)
- **æ¶æ„**: 256 Experts MoE
- **è§„æ¨¡**: tp_degree=64

</div>
<div>

### âš¡ æŒ‘æˆ˜
- âŒ DGEç¼–è¯‘é™åˆ¶
- âŒ æ¶æ„å·®å¼‚å·¨å¤§
- âŒ ç‰ˆæœ¬å…¼å®¹æ€§
- âŒ ç²¾åº¦æŸå¤±é£é™©

</div>
</div>

---

## æ¨¡å‹è§„æ¨¡å¯¹æ¯”

| ç»´åº¦ | Qwen3-30B | MiniMax M2 | å¢é•¿ |
|------|-----------|-----------|------|
| **å‚æ•°é‡** | 30B | 230B | **+667%** |
| **ä¸“å®¶æ•°** | 128 | 256 | **+100%** |
| **å±‚æ•°** | 32 | 62 | **+94%** |
| **éšè—ç»´åº¦** | 4096 | 6144 | **+50%** |
| **TP Degree** | 32 | 64 | **+100%** |

---

<!-- _class: lead -->

# 2. æ¨¡å‹æ¶æ„å¯¹æ¯”åˆ†æ

---

## å…³é”®æ¶æ„å·®å¼‚

### ğŸ”´ é—®é¢˜1: Intermediate Size

```
Qwen3:    14336 / 32 = 448 âœ… (>= 32)
MiniMax:   1536 / 64 =  24 âŒ (< 32)
                           â†“
              è§¦å‘ DGE ç¼–è¯‘é”™è¯¯
```

### ğŸ”´ é—®é¢˜2: QK Normalization

```python
# Qwen3: Shared norm
q_norm: [128]           # æ‰€æœ‰headså…±äº«

# MiniMax M2: Per-head norm
q_norm: [6144] = [48Ã—128]  # æ¯ä¸ªheadç‹¬ç«‹
```

---

## æ¶æ„å¯¹æ¯”å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Qwen3 MoE (30B)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attention: 32 heads â†’ Shared QK Norm               â”‚
â”‚ MoE: 128 experts â†’ intermediate=14336              â”‚
â”‚ TP=32 â†’ 14336/32=448 âœ…                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                MiniMax M2 (230B)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attention: 48 heads â†’ Per-head QK Norm âš ï¸          â”‚
â”‚ MoE: 256 experts â†’ intermediate=1536               â”‚
â”‚ TP=64 â†’ 1536/64=24 âŒ DGEé™åˆ¶                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

<!-- _class: lead -->

# 3. æŠ€æœ¯å®æ–½è·¯çº¿

---

## æ•´ä½“æµç¨‹

```
1ï¸âƒ£ åˆ›å»ºæ¨¡å‹æ–‡ä»¶ç»“æ„
   â””â”€ modeling_minimax_m2.py
   â””â”€ configuration_minimax_m2.py
   â””â”€ generation_demo.py

2ï¸âƒ£ é…ç½®Neuronå‚æ•°
   â””â”€ tp_degree=64
   â””â”€ blockwise_matmul_config

3ï¸âƒ£ è§£å†³DGEç¼–è¯‘é”™è¯¯ â­
   â””â”€ å‘ç°é…ç½®ä¼ æ’­å¤±è´¥
   â””â”€ moe.py â†’ moe_v2.py

4ï¸âƒ£ è§£å†³æƒé‡åŠ è½½é”™è¯¯ â­
   â””â”€ QK normå½¢çŠ¶è½¬æ¢
   â””â”€ RouterConfig dtype

5ï¸âƒ£ æˆåŠŸè¿è¡Œ âœ…
```

---

## æ–‡ä»¶ä¿®æ”¹æ¸…å•

| æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ | é‡è¦æ€§ |
|------|---------|--------|
| **modeling_minimax_m2.py** | MoEåˆå§‹åŒ–, QK normè½¬æ¢ | â­â­â­â­â­ |
| **config.py** | RouterConfig dtypeè½¬æ¢ | â­â­â­â­ |
| **hf_adapter.py** | GenerationMixinç»§æ‰¿ | â­â­â­â­ |
| **modeling_minimax_m2_gpu.py** | transformerså…¼å®¹ | â­â­â­ |
| **generation_demo.py** | é…ç½®å‚æ•° | â­â­ |

---

<!-- _class: lead -->

# 4. å…³é”®é—®é¢˜æ·±åº¦å‰–æ

---

## ğŸ”¥ é—®é¢˜1: DGEç¼–è¯‘é”™è¯¯

### é”™è¯¯ä¿¡æ¯
```
[NLA001] Unhandled exception with message:
tensorizer(output tensor: float32<24 x 1536> $237367[block_idx_64])
Instruction DMACopy I-237367-0: Invalid Shape for Scalar DGE!
```

### æ ¹æœ¬åŸå› 
- **DGEè¦æ±‚**: `intermediate_size / tp_degree >= 32`
- **å®é™…æƒ…å†µ**: `1536 / 64 = 24 < 32` âŒ
- **è§¦å‘æ¡ä»¶**: ä½¿ç”¨NKI kernelçš„blockwise matmul

---

## è§£å†³æ–¹æ¡ˆ: use_torch_block_wise

### âŒ é”™è¯¯é…ç½®ï¼ˆæœªç”Ÿæ•ˆï¼‰

```python
# é…ç½®çœ‹èµ·æ¥æ­£ç¡®
neuron_config = MoENeuronConfig(
    blockwise_matmul_config={
        'use_torch_block_wise': True
    }
)

# ä½†å®é™…ä¸Š...
expert_mlps.blockwise_matmul_config.use_torch_block_wise = False âŒ
```

**ä¸ºä»€ä¹ˆï¼Ÿ** ä½¿ç”¨äº†é”™è¯¯çš„ `moe.py` è€Œé `moe_v2.py`

---

## æ ¹å› : moe vs moe_v2

<div class="columns">
<div>

### âŒ moe.py (æ—§ç‰ˆ)
```python
# ExpertMLPs
def __init__(
    self,
    use_torch_block_wise=False,  # é»˜è®¤False
    ...
):
    # å‚æ•°è¢«è¦†ç›–
```

**é—®é¢˜**: é…ç½®å¯¹è±¡æœªä¼ é€’ï¼Œä½¿ç”¨é»˜è®¤å€¼

</div>
<div>

### âœ… moe_v2.py (æ–°ç‰ˆ)
```python
# ExpertMLPsV2
def __init__(
    self,
    blockwise_matmul_config,  # å¯¹è±¡
    ...
):
    self.config = blockwise_matmul_config
```

**æ­£ç¡®**: ç›´æ¥ä¼ é€’é…ç½®å¯¹è±¡

</div>
</div>

---

## ä¿®å¤ä»£ç 

```python
# âŒ é”™è¯¯
from neuronx_distributed_inference.modules.moe import initialize_moe_module

self.mlp = initialize_moe_module(
    config=config,
    num_experts=...,  # æ—§API
    top_k=...,
)

# âœ… æ­£ç¡®
from neuronx_distributed_inference.modules.moe_v2 import initialize_moe_module

self.mlp = initialize_moe_module(config=config)  # æ–°API
```

---

## ğŸ”¥ é—®é¢˜2: QK Normå½¢çŠ¶ä¸åŒ¹é…

### é”™è¯¯ä¿¡æ¯
```
RuntimeError: Incorrect tensor shape at checkpoint key
  layers.0.self_attn.k_layernorm.weight:
    received 1024, expected 128
  layers.0.self_attn.q_layernorm.weight:
    received 6144, expected 128
```

### æ•°æ®å¯¹æ¯”

| é¡¹ç›® | Qwen3 | MiniMax M2 |
|------|-------|-----------|
| **å®ç°** | Shared | Per-head |
| **k_norm** | [128] | [1024] = [8Ã—128] |
| **q_norm** | [128] | [6144] = [48Ã—128] |

---

## è§£å†³æ–¹æ¡ˆ: å–å¹³å‡å€¼

```python
# Step 1: Reshape
k_norm_full = state_dict["k_norm.weight"]  # [1024]
k_norm_reshaped = k_norm_full.reshape(8, 128)  # [8, 128]

# Step 2: Average across heads
k_norm_shared = k_norm_reshaped.mean(dim=0)  # [128]

# å¯¹q_normåšåŒæ ·å¤„ç†
q_norm_full = state_dict["q_norm.weight"]  # [6144]
q_norm_reshaped = q_norm_full.reshape(48, 128)  # [48, 128]
q_norm_shared = q_norm_reshaped.mean(dim=0)  # [128]
```

---

## âš ï¸ å¹³å‡åŒ–çš„å½±å“

```
Per-head norm (è®­ç»ƒæ—¶):
  head_0: [0.8, 1.0, 1.2, ...]
  head_1: [1.1, 0.9, 1.3, ...]
  head_2: [0.9, 1.1, 1.0, ...]
         â†“ mean(dim=0)
Shared norm (æ¨ç†æ—¶):
  shared: [0.93, 1.0, 1.17, ...]

âŒ é—®é¢˜: ä¸¢å¤±äº†head-specificä¿¡æ¯
âŒ åæœ: Attentionåˆ†å¸ƒæ”¹å˜ â†’ ç”Ÿæˆè´¨é‡ä¸‹é™
```

---

## ğŸ”¥ é—®é¢˜3: transformersç‰ˆæœ¬å†²çª

### ç‰ˆæœ¬çŸ©é˜µ

| ç‰ˆæœ¬ | masking_utils | GenerationMixin | FP8é‡åŒ–æ£€æŸ¥ |
|------|--------------|----------------|------------|
| 4.51.3 | âŒ | âœ… | âŒ |
| 4.52-4.49 | âœ… | âœ… | âŒ |
| 4.50+ | âœ… | âŒ | âœ… |
| **4.57.1** | âœ… | âŒ | âœ… |

**æ— æ³•é™çº§ â†’ éœ€è¦å…¼å®¹å±‚**

---

## è§£å†³æ–¹æ¡ˆ: å¤šé‡ç»§æ‰¿

```python
# âŒ é”™è¯¯ (4.50+ä¼šå¤±è´¥)
class HuggingFaceGenerationAdapter(PreTrainedModel):
    def generate(self, ...):
        return super().generate(...)  # AttributeError!

# âœ… æ­£ç¡®
from transformers.generation import GenerationMixin

class HuggingFaceGenerationAdapter(GenerationMixin, PreTrainedModel):
    def __init__(self, model, ...):
        PreTrainedModel.__init__(self, hf_config)
        # GenerationMixinåœ¨å‰ï¼Œç¡®ä¿generate()å¯ç”¨
```

---

<!-- _class: lead -->

# 5. æ€§èƒ½å½±å“è¯„ä¼°

---

## å½±å“å› ç´ åˆ†æ

```
ç”Ÿæˆè´¨é‡ä¸‹é™ =
    QK Normå¹³å‡åŒ– (60%)
  + FP8ç²¾åº¦æŸå¤± (30%)
  + PyTorch blockwiseæ€§èƒ½ (10%)
```

### ğŸ”´ ä¸»è¦å½±å“: QK Normå¹³å‡åŒ–

- **æœºåˆ¶ç ´å**: Multi-head attentioné€€åŒ–
- **è®­ç»ƒ-æ¨ç†mismatch**: åˆ†å¸ƒå®Œå…¨ä¸åŒ
- **æ— æ³•æ¢å¤**: Per-headä¿¡æ¯æ°¸ä¹…ä¸¢å¤±

---

## QK Normå½±å“æ·±åº¦åˆ†æ

<div class="columns">
<div>

### è®­ç»ƒæ—¶ (Per-head)
```python
# æ¯ä¸ªheadç‹¬ç«‹å½’ä¸€åŒ–
for i in range(48):
    Q[i] = norm_i(Q[i])
    K[i] = norm_i(K[i])

# å„headå­¦ä¹ ä¸åŒç‰¹å¾
attention_i = softmax(Q[i]K[i]^T)
```

</div>
<div>

### æ¨ç†æ—¶ (Shared)
```python
# æ‰€æœ‰headç”¨åŒä¸€å¥—å‚æ•°
Q_all = norm_shared(Q_all)
K_all = norm_shared(K_all)

# âŒ Headç‰¹å¼‚æ€§ä¸¢å¤±
# âŒ Attention scoreså¤±çœŸ
# âŒ ç”Ÿæˆè´¨é‡ä¸‹é™
```

</div>
</div>

---

## FP8ç²¾åº¦æŸå¤±

### ç±»å‹è½¬æ¢é“¾

```
åŸå§‹æƒé‡ (FP32/BF16)
    â†“ è®­ç»ƒæ—¶é‡åŒ–
FP8 (E4M3) checkpoint
    â†“ åŠ è½½è½¬æ¢
BF16 (åˆ é™¤é‡åŒ–é…ç½®)
    â†“ Neuronè®¡ç®—
BF16 è¾“å‡º
```

### ç²¾åº¦å¯¹æ¯”

| æ ¼å¼ | ç¬¦å· | æŒ‡æ•° | å°¾æ•° | åŠ¨æ€èŒƒå›´ |
|------|------|------|------|---------|
| **FP8** | 1 | 4 | 3 | Â±448 |
| **BF16** | 1 | 8 | 7 | Â±3.4e38 |
| **æŸå¤±** | - | -50% | -57% | æ˜¾è‘— |

---

## PyTorch vs NKI Kernel

### æ€§èƒ½å¯¹æ¯”ï¼ˆä¼°ç®—ï¼‰

```
NKI Kernel (DGEä¼˜åŒ–):
  âœ… ç¡¬ä»¶çº§ä¼˜åŒ–
  âœ… å†…å­˜å¸ƒå±€ä¼˜åŒ–
  âœ… ä½å»¶è¿Ÿ

PyTorchå®ç° (use_torch_block_wise):
  âŒ é€šç”¨å®ç°
  âŒ æœªä¼˜åŒ–å†…å­˜
  âš ï¸  å»¶è¿Ÿå¢åŠ 20-40%
```

**Expert MLPæ˜¯MoEçš„æ€§èƒ½ç“¶é¢ˆ**

---

## æ€§èƒ½åŸºå‡†

| æŒ‡æ ‡ | Qwen3-30B | MiniMax M2 | å·®è· |
|------|----------|-----------|------|
| **ç¼–è¯‘æ—¶é—´** | ~40 min | ~50 min | +25% |
| **åŠ è½½æ—¶é—´** | ~180 s | ~233 s | +29% |
| **Warmup** | ~2 s | ~2.4 s | +20% |
| **Token/s** | ~15 | ~10 | -33% |
| **è¾“å‡ºè´¨é‡** | âœ… æ­£å¸¸ | âŒ å¾…ä¼˜åŒ– | ä¸¥é‡ |

---

<!-- _class: lead -->

# 6. æˆæœå±•ç¤º

---

## âœ… é˜¶æ®µæ€§æˆæœ

<div class="columns">
<div>

### æŠ€æœ¯çªç ´
- âœ… **DGEé™åˆ¶**: ç»•è¿‡ç¼–è¯‘éšœç¢
- âœ… **é…ç½®ä¼ æ’­**: è¯†åˆ«moe_v2é—®é¢˜
- âœ… **ç‰ˆæœ¬å…¼å®¹**: å®Œæ•´å…¼å®¹å±‚
- âœ… **æƒé‡åŠ è½½**: FP8â†’BF16è½¬æ¢

</div>
<div>

### å®é™…æˆæœ
- âœ… **ç¼–è¯‘æˆåŠŸ**: 62å±‚å®Œæ•´ç¼–è¯‘
- âœ… **åŠ è½½æˆåŠŸ**: 230Bæƒé‡åˆ†ç‰‡
- âœ… **æ¨ç†è¿è¡Œ**: ç”Ÿæˆæµç¨‹å®Œæ•´
- âš ï¸  **è´¨é‡å¾…ä¼˜åŒ–**: éœ€è¿›ä¸€æ­¥è°ƒä¼˜

</div>
</div>

---

## ç¼–è¯‘æ—¥å¿—éªŒè¯

```bash
# âœ… å…³é”®æˆåŠŸæ ‡å¿—
INFO:Neuron:Generating HLOs...

UserWarning: use_torch_block_wise set, using torch implementation
                    â†‘
              é…ç½®ç”Ÿæ•ˆï¼

INFO:Neuron:Generated all HLOs in 32.25 seconds
INFO:Neuron:Compilation completed successfully

# âœ… åŠ è½½æˆåŠŸ
INFO:Neuron:Done Sharding weights in 211.49 seconds
INFO:Neuron:Warmup completed in 2.39 seconds

Generating outputs... âœ…
```

---

## å…³é”®ä»£ç ä¿®æ”¹ç»Ÿè®¡

| ç±»åˆ« | æ–‡ä»¶æ•° | ä¿®æ”¹è¡Œæ•° | æ ¸å¿ƒä¿®æ”¹ |
|------|--------|---------|---------|
| **MoEåˆå§‹åŒ–** | 1 | ~20 | â­â­â­â­â­ |
| **QK Normè½¬æ¢** | 1 | ~25 | â­â­â­â­â­ |
| **é…ç½®ä¿®å¤** | 1 | ~15 | â­â­â­â­ |
| **ç‰ˆæœ¬å…¼å®¹** | 2 | ~30 | â­â­â­â­ |
| **æ€»è®¡** | 5 | ~90 | - |

**ä»£ç æ”¹åŠ¨é‡å°ï¼Œä½†æ¯ä¸€å¤„éƒ½è‡³å…³é‡è¦**

---

<!-- _class: lead -->

# 7. ä¼˜åŒ–å»ºè®®ä¸å±•æœ›

---

## çŸ­æœŸä¼˜åŒ– (1-2å‘¨)

### ğŸ¯ ä¼˜å…ˆçº§1: Per-head QK Norm

```python
# æ–¹æ¡ˆ: ä¿®æ”¹Neuron attentionæ¨¡å—
class NeuronMiniMaxM2Attention:
    def __init__(self, config):
        # åˆ›å»ºper-head norm
        self.q_layernorm = nn.ModuleList([
            RMSNorm(head_dim) for _ in range(num_heads)
        ])

    def forward(self, Q, K, V):
        # å¯¹æ¯ä¸ªheadç‹¬ç«‹å½’ä¸€åŒ–
        for i, q_head in enumerate(Q.split(head_dim, -1)):
            Q_normalized[i] = self.q_layernorm[i](q_head)
```

**é¢„æœŸæ•ˆæœ**: æ¢å¤60%çš„è´¨é‡æŸå¤± â­â­â­â­â­

---

## çŸ­æœŸä¼˜åŒ– (ç»­)

### ğŸ¯ ä¼˜å…ˆçº§2: æ¢å¤FP8ç²¾åº¦

**æ–¹æ¡ˆA**: ä¿®æ”¹é‡åŒ–æ£€æŸ¥
```python
# quantizer_finegrained_fp8.py
def validate_environment(self, ...):
    if torch_neuronx.is_available():
        return  # Neuronæ”¯æŒFP8
```

**æ–¹æ¡ˆB**: ä½¿ç”¨æœªé‡åŒ–checkpoint
```bash
huggingface-cli download MiniMax/MiniMax-M2-unquantized
```

**é¢„æœŸæ•ˆæœ**: æ¢å¤30%çš„è´¨é‡æŸå¤± â­â­â­â­

---

## ä¸­æœŸä¼˜åŒ– (1-2æœˆ)

### ğŸ¯ å¯ç”¨NKI Kernel

**æŒ‘æˆ˜**: å¦‚ä½•ç»•è¿‡DGEé™åˆ¶ï¼Ÿ

1. **è°ƒæ•´intermediate_size** (éœ€é‡æ–°è®­ç»ƒ) âŒ
2. **é™ä½tp_degree** (ä¼šOOM) âŒ
3. **è”ç³»AWS Neuronå›¢é˜Ÿ** (é™ä½DGEè¦æ±‚) âœ…

**é¢„æœŸæ•ˆæœ**: æå‡20-40%æ¨ç†é€Ÿåº¦ â­â­â­

---

## ä¸­æœŸä¼˜åŒ– (ç»­)

### ğŸ¯ ä¼˜åŒ–MoEé…ç½®

```python
# å°è¯•çœŸæ­£å¯ç”¨Expert Parallelism
neuron_config = MoENeuronConfig(
    tp_degree=64,
    moe_ep_degree=8,   # 8ä¸ªexpertå¹¶è¡Œç»„
    moe_tp_degree=8,   # æ¯ç»„8-way TP
)
```

**éœ€è¦éªŒè¯**:
- é…ç½®æ˜¯å¦çœŸçš„ç”Ÿæ•ˆï¼ˆç›®å‰æœªç”Ÿæ•ˆï¼‰
- æ˜¯å¦æ”¹å–„è´Ÿè½½å‡è¡¡
- é€šä¿¡å¼€é”€ vs è®¡ç®—å¹¶è¡Œçš„æƒè¡¡

---

## é•¿æœŸå±•æœ›

### ğŸ”¬ æ··åˆç²¾åº¦ç­–ç•¥

```python
# ä¸åŒç»„ä»¶ç”¨ä¸åŒç²¾åº¦
neuron_config = MoENeuronConfig(
    attention_dtype=torch.bfloat16,    # é«˜ç²¾åº¦
    mlp_dtype=torch.float8_e4m3fn,    # èŠ‚çœå†…å­˜
    norm_dtype=torch.float32,          # å…³é”®æ“ä½œ
)
```

### ğŸ“ æ¨¡å‹è’¸é¦/å¾®è°ƒ

- åœ¨Neuronä¸Šç”¨shared normé‡æ–°å¾®è°ƒ
- è®©æ¨¡å‹é€‚åº”æ–°çš„normalizationæ–¹å¼
- éœ€è¦è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æº

---

## æŠ€æœ¯è·¯çº¿å›¾

```
å½“å‰ (2025-11)
â”œâ”€ âœ… ç¼–è¯‘æˆåŠŸ
â”œâ”€ âœ… åŠ è½½è¿è¡Œ
â””â”€ âš ï¸  è´¨é‡å¾…ä¼˜åŒ–

çŸ­æœŸ (1-2å‘¨)
â”œâ”€ ğŸ¯ Per-head QK Norm
â”œâ”€ ğŸ¯ æ¢å¤FP8ç²¾åº¦
â””â”€ ğŸ“Š è´¨é‡è¯„ä¼°

ä¸­æœŸ (1-2æœˆ)
â”œâ”€ ğŸ¯ å¯ç”¨NKI Kernel
â”œâ”€ ğŸ¯ ä¼˜åŒ–MoEé…ç½®
â””â”€ ğŸ“Š æ€§èƒ½è¯„ä¼°

é•¿æœŸ (3æœˆ+)
â”œâ”€ ğŸ”¬ æ··åˆç²¾åº¦
â”œâ”€ ğŸ“ æ¨¡å‹å¾®è°ƒ
â””â”€ ğŸš€ ç”Ÿäº§éƒ¨ç½²
```

---

<!-- _class: lead -->

# æ€»ç»“ä¸å±•æœ›

---

## æ ¸å¿ƒæˆå°±

<div class="columns">
<div>

### æŠ€æœ¯çªç ´
1. âœ… è¯†åˆ«å¹¶è§£å†³moe_v2é…ç½®é—®é¢˜
2. âœ… è®¾è®¡per-headâ†’sharedè½¬æ¢æ–¹æ¡ˆ
3. âœ… å»ºç«‹å®Œæ•´ç‰ˆæœ¬å…¼å®¹æœºåˆ¶
4. âœ… æ‰“é€šç«¯åˆ°ç«¯æ¨ç†æµç¨‹

</div>
<div>

### å·¥ç¨‹ä»·å€¼
1. ğŸ“– 230B MoEé€‚é…ç»éªŒ
2. ğŸ”§ å¯å¤ç”¨çš„é€‚é…æ¡†æ¶
3. ğŸ“Š è¯¦ç»†çš„é—®é¢˜è¯Šæ–­
4. ğŸ¯ æ¸…æ™°çš„ä¼˜åŒ–è·¯çº¿

</div>
</div>

---

## å…³é”®ç»éªŒ

### âœ¨ æˆåŠŸç»éªŒ
- **é…ç½®è¿½è¸ª**: éªŒè¯é…ç½®æ˜¯å¦çœŸæ­£ç”Ÿæ•ˆ
- **æ¶æ„å¯¹æ¯”**: æ·±å…¥ç†è§£æ¨¡å‹å·®å¼‚
- **æ¸è¿›å¼è°ƒè¯•**: é€æ­¥å®šä½æ ¹æœ¬åŸå› 

### âš ï¸ æ•™è®­
- **ä¸è¦å‡è®¾**: Per-head vs Sharedçš„åŒºåˆ«
- **éªŒè¯é…ç½®**: moe vs moe_v2çš„é™·é˜±
- **ç‰ˆæœ¬ç®¡ç†**: transformerså¿«é€Ÿè¿­ä»£

---

## ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³æ‰§è¡Œ (æœ¬å‘¨)
1. âœ… æŠ€æœ¯æŠ¥å‘Šå·²å®Œæˆ
2. ğŸ”„ å®ç°per-head QK normæ”¯æŒ
3. ğŸ“Š æµ‹è¯•æœªé‡åŒ–checkpoint

### è¿‘æœŸè®¡åˆ’ (æœ¬æœˆ)
1. ğŸ”§ è”ç³»AWS Neuronå›¢é˜Ÿ
2. ğŸ“ˆ æ€§èƒ½åŸºå‡†æµ‹è¯•
3. ğŸ“ æœ€ä½³å®è·µæ–‡æ¡£

---

<!-- _class: lead -->

# Q & A

## æ„Ÿè°¢è†å¬ï¼

**æŠ€æœ¯æŠ¥å‘Š**: `MiniMax_M2_Trainium2_Adaptation_Report.md`
**ä»£ç ä»“åº“**: `/home/ubuntu/neuronx-distributed-inference/`
**è”ç³»æ–¹å¼**: [æ‚¨çš„è”ç³»æ–¹å¼]

---

## é™„å½•: é—®é¢˜è¯Šæ–­æ¸…å•

### ç¼–è¯‘é˜¶æ®µ
- [ ] DGEé”™è¯¯ â†’ æ£€æŸ¥`use_torch_block_wise=True`
- [ ] Importé”™è¯¯ â†’ ç¡®è®¤ä½¿ç”¨`moe_v2`
- [ ] OOMé”™è¯¯ â†’ ç¡®è®¤`tp_degree=64`

### åŠ è½½é˜¶æ®µ
- [ ] QK normå½¢çŠ¶é”™è¯¯ â†’ æ£€æŸ¥reshapeé€»è¾‘
- [ ] Router dtypeé”™è¯¯ â†’ ç¡®è®¤`to_torch_dtype`è½¬æ¢
- [ ] FP8é‡åŒ–é”™è¯¯ â†’ åˆ é™¤`quantization_config`

### æ¨ç†é˜¶æ®µ
- [ ] GenerationMixiné”™è¯¯ â†’ ç¡®è®¤ç»§æ‰¿é¡ºåº
- [ ] è¾“å‡ºè´¨é‡å·® â†’ æ£€æŸ¥QK normæ˜¯å¦averaged

---

## é™„å½•: å¿«é€Ÿå‚è€ƒ

### å…³é”®é…ç½®
```python
neuron_config = MoENeuronConfig(
    tp_degree=64,
    blockwise_matmul_config={
        'use_torch_block_wise': True,  # æ ¸å¿ƒ
    }
)
```

### éªŒè¯å‘½ä»¤
```bash
# ç¼–è¯‘
python3 generation_minimax_m2_demo.py

# è·³è¿‡ç¼–è¯‘
python3 generation_minimax_m2_demo.py --skip-compile
```

---

<!-- _class: lead -->

# è°¢è°¢ï¼

**æŠ€æœ¯æ”¯æŒ**: AWS Neuron Team
**è´¡çŒ®è€…**: [æ‚¨çš„å›¢é˜Ÿ]
**æ—¥æœŸ**: 2025-11-05
